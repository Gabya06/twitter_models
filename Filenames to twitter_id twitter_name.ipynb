{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto\n",
    "from twitter.models import TwitterUser\n",
    "from mappings.models import UserMapping\n",
    "from lib.utils import parse_dash_separated_date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S3_CONNECTION = boto.connect_s3(settings.AMAZON_S3_KEY,\n",
    "                                settings.AMAZON_S3_SECRET)\n",
    "S_BUCKET = S3_CONNECTION.get_bucket('shareablee')\n",
    "\n",
    "bucket_name = 'shareablee' # for getting data\n",
    "bucket_tmp = 'shareablee-hive' # for writing data\n",
    "\n",
    "prefix = 'tmp/twitter/'\n",
    "write_key_pattern = '_DONE'\n",
    "\n",
    "TWITTER = 'twitter'\n",
    "\n",
    "SERVICES = [TWITTER]\n",
    "\n",
    "SERVICE_DICT = dict(\n",
    "   [\n",
    "       (\n",
    "           service,\n",
    "           UserMapping.objects.all().prefetch_related(service)\n",
    "       )\n",
    "       for service in SERVICES\n",
    "   ]\n",
    ")\n",
    "\n",
    "START_DATE = '2016-01-01'\n",
    "END_DATE = '2016-01-31'\n",
    "\n",
    "start_date = parse_dash_separated_date(START_DATE)\n",
    "end_date = parse_dash_separated_date(END_DATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_id = flagged_prop\n",
    "tmp_list = SERVICE_DICT.get(TWITTER).filter(twitter__user_id__in = twitter_id, twitter__isnull=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'instagram_id': u'173776491', 'name': u'DIRECTV', u'tumblr_id': None, u'twitter_id': 445, u'google_plus_id': u'118252990442481680236', u'facebook_id': 298, 'hidden': False, u'id': 445, u'youtube_id': u'UCHKj3ZT5E7wvPKRXhFAWhCQ'}, {u'instagram_id': u'2289588', 'name': u'Hallmark Channel USA', u'tumblr_id': 609, u'twitter_id': 824, u'google_plus_id': u'109189303738388047477', u'facebook_id': 2426, 'hidden': False, u'id': 823, u'youtube_id': u'UC5T-sc4bz1eAEgMIamLLV6w'}, {u'instagram_id': u'18464866', 'name': u'InStyle', u'tumblr_id': 829, u'twitter_id': 930, u'google_plus_id': u'114158576114160263892', u'facebook_id': 1979, 'hidden': False, u'id': 929, u'youtube_id': u'UCj6iVt0NLGyj406r2kD161g'}, {u'instagram_id': u'185036484', 'name': u'Essence Online', u'tumblr_id': None, u'twitter_id': 959, u'google_plus_id': None, u'facebook_id': 2840, 'hidden': False, u'id': 958, u'youtube_id': u'UC_b9CfN5Yeb_c2hQNRGKXUw'}, {u'instagram_id': u'549069015', 'name': u'ABC11 WTVD', u'tumblr_id': None, u'twitter_id': 1211, u'google_plus_id': u'107454178249921583889', u'facebook_id': 4510, 'hidden': False, u'id': 1210, u'youtube_id': u'UCe7cIhm4_RWsThRzBCXtmOQ'}, {u'instagram_id': u'1385592527', 'name': u'Cartoon Network (Global)', u'tumblr_id': 1134, u'twitter_id': 1335, u'google_plus_id': u'116959562941117489715', u'facebook_id': 1709, 'hidden': False, u'id': 1334, u'youtube_id': u'UCMsgXPD3wzzt8RxHJmXH7hQ'}, {u'instagram_id': u'5087794', 'name': u'TIME', u'tumblr_id': 7, u'twitter_id': 1593, u'google_plus_id': u'110038350445855508357', u'facebook_id': 129, 'hidden': False, u'id': 1592, u'youtube_id': u'UC8Su5vZCXWRag13H53zWVwA'}, {u'instagram_id': u'51707702', 'name': u'BET', u'tumblr_id': 898, u'twitter_id': 1635, u'google_plus_id': u'108884352704624324138', u'facebook_id': 1955, 'hidden': False, u'id': 8306, u'youtube_id': u'UCcVqCJ_9owb1zM43vqswMNQ'}, {u'instagram_id': u'205593849', 'name': u'NFL', u'tumblr_id': None, u'twitter_id': 1669, u'google_plus_id': u'102139249949018843498', u'facebook_id': 3053, 'hidden': False, u'id': 1669, u'youtube_id': u'UCDVYQ4Zhbm3S2dlz7P1GBDg'}, {u'instagram_id': u'187862194', 'name': u'Land Rover (US)', u'tumblr_id': 577, u'twitter_id': 2239, u'google_plus_id': u'100679443999083017902', u'facebook_id': 210, 'hidden': False, u'id': 2243, u'youtube_id': u'UCSX22m92Fb8T8UqyFbUw3hQ'}, {u'instagram_id': u'24579428', 'name': u'Univision', u'tumblr_id': 618, u'twitter_id': 2297, u'google_plus_id': u'106352935507714859879', u'facebook_id': 2550, 'hidden': False, u'id': 2301, u'youtube_id': u'UCcEWv_J2SEU8XO2tEm4Phgw'}, {u'instagram_id': u'1022625', 'name': u'Billboard', u'tumblr_id': 795, u'twitter_id': 2925, u'google_plus_id': u'104684949156835023056', u'facebook_id': 2592, 'hidden': False, u'id': 2932, u'youtube_id': u'UCsVcseUYbYjldc-XgcsiEbg'}, {u'instagram_id': u'9791606', 'name': u'Coach', u'tumblr_id': None, u'twitter_id': 3667, u'google_plus_id': u'106118659434268147674', u'facebook_id': 1053, 'hidden': False, u'id': 3666, u'youtube_id': u'UC0Ecp-GtoM5xxRC4hvSLirg'}, {u'instagram_id': u'1907035', 'name': u'MTV', u'tumblr_id': 899, u'twitter_id': 4272, u'google_plus_id': u'107535994725801213380', u'facebook_id': 1936, 'hidden': False, u'id': 4277, u'youtube_id': u'UCxAICW_LdkfFYwTqTHHE0vg'}, {u'instagram_id': u'317111047', 'name': u'ABC7', u'tumblr_id': None, u'twitter_id': 4450, u'google_plus_id': u'108008721040270303513', u'facebook_id': 2691, 'hidden': False, u'id': 4455, u'youtube_id': u'UCVxBA3Cbu3pm8w8gEIoMEog'}, {u'instagram_id': u'28759374', 'name': u'People.com', u'tumblr_id': 812, u'twitter_id': 4579, u'google_plus_id': u'103085706090803465392', u'facebook_id': 120, 'hidden': False, u'id': 4588, u'youtube_id': u'UCGbQJy-531_5vfphay-rChQ'}, {u'instagram_id': u'217723373', 'name': u'CNN', u'tumblr_id': None, u'twitter_id': 4929, u'google_plus_id': u'117515799321987910349', u'facebook_id': 114, 'hidden': False, u'id': 4943, u'youtube_id': u'UCupvZG-5ko_eiXAupbDfxWw'}, {u'instagram_id': u'399069694', 'name': u'Bustle', u'tumblr_id': 1069, u'twitter_id': 8474, u'google_plus_id': u'108618019202547741903', u'facebook_id': 11207, 'hidden': False, u'id': 8513, u'youtube_id': u'UCHcIcCNAULM4qWs6-9Iy-Tw'}, {u'instagram_id': u'241904423', 'name': u'Ringling Bros. and Barnum & Bailey Circus', u'tumblr_id': None, u'twitter_id': 12590, u'google_plus_id': u'108020971295105925599', u'facebook_id': 16570, 'hidden': False, u'id': 12679, u'youtube_id': u'UCMMI3ZcIs1MrGu0uoI6Y7tQ'}, {u'instagram_id': u'196876753', 'name': u'Aqu\\xed y Ahora', u'tumblr_id': None, u'twitter_id': 13029, u'google_plus_id': None, u'facebook_id': 17201, 'hidden': False, u'id': 13254, u'youtube_id': None}, '...(remaining elements truncated)...']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list.values_list('twitter__user_id', flat = True)\n",
    "tmp_list.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect_to_s3():\n",
    "    \"\"\" Return a connection to Shareablee's S3 resource\n",
    "    \"\"\"\n",
    "    key = settings.AMAZON_S3_KEY\n",
    "    secret = settings.AMAZON_S3_SECRET\n",
    "    return boto.connect_s3(key, secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_kwargs = {\n",
    "    'header': 1,\n",
    "    'sep': ',',\n",
    "    'engine': 'c',\n",
    "    'header': 0,\n",
    "    'escapechar': '\\\\',\n",
    "    'usecols' : ['time', 'impressions','retweets']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = connect_to_s3()\n",
    "key = \"/\".join(['twitter_analytics', '1.1', 'analytics_reports/']) \n",
    "res = list(S_BUCKET.list(prefix=key)) # list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_prop_id(filename):\n",
    "    \"\"\" Returns property_id from filename\n",
    "    \"\"\"\n",
    "    return filename.key.split(\"/\")[-1].split('_')[0]\n",
    "\n",
    "\n",
    "# def get_keys(conn, bucket_name, key_pattern, **kwargs):\n",
    "#     \"\"\" Returns an in-memory pandas database by matching s3 key names to a regex pattern\n",
    "#     \"\"\"\n",
    "#     bucket = conn.get_bucket(bucket_name)\n",
    "#     prefix = kwargs.get('prefix', '')\n",
    "    \n",
    "#     results = pd.DataFrame(columns=pd_kwargs['names'])\n",
    "    \n",
    "#     for k in bucket.list(prefix=prefix, delimiter=\"/\"):\n",
    "#         matched = re.search(re.compile(key_pattern), k.name)\n",
    "#         if matched:\n",
    "#             print 'matched!', k.name\n",
    "#             data = pd.read_csv(k, **pd_kwargs)\n",
    "#             results = results.append(data)\n",
    "\n",
    "#     print results.sort(columns=['users'], ascending=False).head()\n",
    "    \n",
    "#     return results\n",
    "\n",
    "def write_key(data, conn, bucket_name, **kwargs):\n",
    "    \"\"\" Writes data from a pandas dataframe to an S3 key\n",
    "    \"\"\"\n",
    "    bucket = conn.get_bucket(bucket_tmp)\n",
    "    key = boto.s3.key.Key(bucket)\n",
    "    output_prefix = kwargs.get('output_prefix', '')\n",
    "\n",
    "    tmp_file = io.BytesIO()\n",
    "    data.to_csv(tmp_file, encoding='utf-8')\n",
    "    tmp_file.seek(0)\n",
    "    key.key = output_prefix\n",
    "    key.set_contents_from_file(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flagged_prop = ['30309979', '18342955', '16374678','119606058','16560657', '226299107',\n",
    "'9695312', '32448740', '1426645165', '21308602','759251','73200694','634784951','14946736','27677483',\n",
    "'25053299','436171805','25453312','14934818','192981351','2367911','19426551','25589776','223525053',\n",
    "                '5988062','14293310','40924038','15513910']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_names = [i.key.split(\"/\")[-1] for i in res if get_prop_id(i) in flagged_prop]\n",
    "\n",
    "filtered_names = [i for i in  file_names if i.split('_')[2].split(\"-\")[0] =='2016' \n",
    "                  if i.split('_')[2].split(\"-\")[1] =='01' or i.split('_')[2].split(\"-\")[1] =='02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = []\n",
    "def filter_weeks(x):\n",
    "    \"\"\" Returns list of files with the below timestamps\n",
    "    \"\"\"\n",
    "    start_week = x.split(\"_\")[2]\n",
    "    end_week = x.split(\"_\")[3]\n",
    "    week_1 = ['2016-01-01', '2016-01-08']\n",
    "    week_2 = ['2016-01-09', '2016-01-16']\n",
    "    week_3 = ['2016-01-17', '2016-01-24']\n",
    "    week_4 = ['2016-01-26', '2016-02-02']\n",
    "    date_part = x.split('_')[2:4]\n",
    "    if date_part in [week_1, week_2, week_3, week_4]:\n",
    "        tmp.append(x)\n",
    "    else:\n",
    "        pass\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_fans_df = pd.DataFrame(columns=['twitter_id', 'fans'])\n",
    "def get_tw_fans(user_pk, **kwargs):\n",
    "    tw_ids = []\n",
    "    tw_fans = []\n",
    "#    user = SERVICE_DICT.get(TWITTER).filter(twitter__pk=user_pk, twitter__isnull=False).first().twitter\n",
    "    tmp_list = SERVICE_DICT.get(TWITTER).filter(twitter__user_id__in = twitter_id, twitter__isnull=False)\n",
    "    for user in tmp_list:\n",
    "        user.twitter.set_date_range(start_date, end_date) \n",
    "        stats = user.twitter.stats()\n",
    "        fans = stats.get('latest_followers', 0)\n",
    "        tw_ids.append(user.twitter.user_id)\n",
    "        tw_fans.append(fans)\n",
    "    tw_fans_df['twitter_id'] = tw_ids\n",
    "    tw_fans_df['fans'] = tw_fans\n",
    "    return tw_fans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>fans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14946736</td>\n",
       "      <td>189456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25453312</td>\n",
       "      <td>114591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14934818</td>\n",
       "      <td>3732958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27677483</td>\n",
       "      <td>201755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18342955</td>\n",
       "      <td>114958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  twitter_id     fans\n",
       "0   14946736   189456\n",
       "1   25453312   114591\n",
       "2   14934818  3732958\n",
       "3   27677483   201755\n",
       "4   18342955   114958"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get twitter follower count (fans) \n",
    "tw_fans_df = get_tw_fans(flagged_prop)\n",
    "tw_fans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119606058 Done! \n",
      "\n",
      "119606058 Done! \n",
      "\n",
      "119606058 Done! \n",
      "\n",
      "119606058 Done! \n",
      "\n",
      "1426645165 Done! \n",
      "\n",
      "1426645165 Done! \n",
      "\n",
      "1426645165 Done! \n",
      "\n",
      "1426645165 Done! \n",
      "\n",
      "14293310 Done! \n",
      "\n",
      "14293310 Done! \n",
      "\n",
      "14293310 Done! \n",
      "\n",
      "14293310 Done! \n",
      "\n",
      "14934818 Done! \n",
      "\n",
      "14934818 Done! \n",
      "\n",
      "14934818 Done! \n",
      "\n",
      "14934818 Done! \n",
      "\n",
      "14946736 Done! \n",
      "\n",
      "14946736 Done! \n",
      "\n",
      "14946736 Done! \n",
      "\n",
      "14946736 Done! \n",
      "\n",
      "15513910 Done! \n",
      "\n",
      "15513910 Done! \n",
      "\n",
      "15513910 Done! \n",
      "\n",
      "15513910 Done! \n",
      "\n",
      "16374678 Done! \n",
      "\n",
      "16374678 Done! \n",
      "\n",
      "16374678 Done! \n",
      "\n",
      "16374678 Done! \n",
      "\n",
      "16560657 Done! \n",
      "\n",
      "16560657 Done! \n",
      "\n",
      "16560657 Done! \n",
      "\n",
      "16560657 Done! \n",
      "\n",
      "18342955 Done! \n",
      "\n",
      "18342955 Done! \n",
      "\n",
      "18342955 Done! \n",
      "\n",
      "18342955 Done! \n",
      "\n",
      "192981351 Done! \n",
      "\n",
      "192981351 Done! \n",
      "\n",
      "192981351 Done! \n",
      "\n",
      "192981351 Done! \n",
      "\n",
      "19426551 Done! \n",
      "\n",
      "19426551 Done! \n",
      "\n",
      "19426551 Done! \n",
      "\n",
      "19426551 Done! \n",
      "\n",
      "21308602 Done! \n",
      "\n",
      "21308602 Done! \n",
      "\n",
      "21308602 Done! \n",
      "\n",
      "21308602 Done! \n",
      "\n",
      "223525053 Done! \n",
      "\n",
      "223525053 Done! \n",
      "\n",
      "223525053 Done! \n",
      "\n",
      "223525053 Done! \n",
      "\n",
      "226299107 Done! \n",
      "\n",
      "226299107 Done! \n",
      "\n",
      "226299107 Done! \n",
      "\n",
      "226299107 Done! \n",
      "\n",
      "2367911 Done! \n",
      "\n",
      "2367911 Done! \n",
      "\n",
      "2367911 Done! \n",
      "\n",
      "2367911 Done! \n",
      "\n",
      "25053299 Done! \n",
      "\n",
      "25053299 Done! \n",
      "\n",
      "25053299 Done! \n",
      "\n",
      "25053299 Done! \n",
      "\n",
      "25453312 Done! \n",
      "\n",
      "25453312 Done! \n",
      "\n",
      "25453312 Done! \n",
      "\n",
      "25453312 Done! \n",
      "\n",
      "25589776 Done! \n",
      "\n",
      "25589776 Done! \n",
      "\n",
      "25589776 Done! \n",
      "\n",
      "25589776 Done! \n",
      "\n",
      "27677483 Done! \n",
      "\n",
      "27677483 Done! \n",
      "\n",
      "27677483 Done! \n",
      "\n",
      "27677483 Done! \n",
      "\n",
      "30309979 Done! \n",
      "\n",
      "30309979 Done! \n",
      "\n",
      "30309979 Done! \n",
      "\n",
      "30309979 Done! \n",
      "\n",
      "32448740 Done! \n",
      "\n",
      "32448740 Done! \n",
      "\n",
      "32448740 Done! \n",
      "\n",
      "32448740 Done! \n",
      "\n",
      "40924038 Done! \n",
      "\n",
      "40924038 Done! \n",
      "\n",
      "40924038 Done! \n",
      "\n",
      "40924038 Done! \n",
      "\n",
      "436171805 Done! \n",
      "\n",
      "436171805 Done! \n",
      "\n",
      "436171805 Done! \n",
      "\n",
      "436171805 Done! \n",
      "\n",
      "5988062 Done! \n",
      "\n",
      "5988062 Done! \n",
      "\n",
      "5988062 Done! \n",
      "\n",
      "5988062 Done! \n",
      "\n",
      "634784951 Done! \n",
      "\n",
      "634784951 Done! \n",
      "\n",
      "634784951 Done! \n",
      "\n",
      "634784951 Done! \n",
      "\n",
      "73200694 Done! \n",
      "\n",
      "73200694 Done! \n",
      "\n",
      "73200694 Done! \n",
      "\n",
      "73200694 Done! \n",
      "\n",
      "759251 Done! \n",
      "\n",
      "759251 Done! \n",
      "\n",
      "759251 Done! \n",
      "\n",
      "759251 Done! \n",
      "\n",
      "9695312 Done! \n",
      "\n",
      "9695312 Done! \n",
      "\n",
      "9695312 Done! \n",
      "\n",
      "9695312 Done! \n",
      "\n",
      "DONE WRITING ALL DATA\n"
     ]
    }
   ],
   "source": [
    "def write_files():\n",
    "    \"\"\" Returns dataframe with: time, impressions, retweets, fans and page_id for Jan 2016\n",
    "        Also write each file to tmp/twitter & all_data to file\n",
    "    \"\"\"\n",
    "    all_data = pd.DataFrame()\n",
    "    for k in res:\n",
    "        if k.name.split(\"/\")[-1] in tmp:\n",
    "            data = pd.read_csv(k, **pd_kwargs)\n",
    "            page_id = k.key.split(\"/\")[-1].split(\"_\")[0]\n",
    "            data['page_id'] = page_id\n",
    "            write_key(data, conn, bucket_tmp, **{'output_prefix': prefix + page_id + write_key_pattern})\n",
    "            print page_id, 'Done!', '\\n'\n",
    "            all_data = all_data.append(data)\n",
    "    # merge results with twitter follower count\n",
    "    all_data = pd.merge(all_data, tw_fans_df, left_on = 'page_id', right_on='twitter_id', how ='left' )\n",
    "    # write all data in one file\n",
    "    write_key(all_data, conn, bucket_tmp, **{'output_prefix': prefix + \"ALL_DATA\" + write_key_pattern})\n",
    "    print \"DONE WRITING ALL DATA\"\n",
    "    return all_data\n",
    "\n",
    "all_data = write_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put results into list - only want twitter_id\n",
    "user_id_list = np.unique([i.key.split(\"/\")[-1].split('_')[0] for i in res]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of user_id, mapping_id, and user_name\n",
    "user_id_list = TwitterUser.objects.filter(user_id__in=user_id_list).values_list('user_id',flat=True)\n",
    "mapping_id_list = TwitterUser.objects.filter(user_id__in=user_id_list).values_list('id',flat=True)\n",
    "user_name_list = TwitterUser.objects.filter(user_id__in=user_id_list).values_list('username',flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_names_dict = dict(zip(user_id_list, user_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store id_names_dict  >> 'names.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict(zip( user_id_list, zip(mapping_id_list, user_name_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
